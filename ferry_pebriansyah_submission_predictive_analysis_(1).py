# -*- coding: utf-8 -*-
"""Ferry_Pebriansyah_submission_predictive_analysis (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15VmGSgVce4DchUUUZhiChVA02JWLrZIu

# Predictive Analysis: Stroke Risk Prediction

- **Nama:** Ferry Pebriansyah
- **Email:** ferryfeb10@gmail.com
- **ID Dicoding:** ferrypebriansyah

# Domain Proyek

Stroke merupakan salah satu penyebab utama kematian dan kecacatan di Indonesia. Penyakit ini terjadi akibat gangguan aliran darah ke otak, yang menyebabkan kerusakan pada jaringan otak dan mengakibatkan gangguan fungsi tubuh, baik secara fisik, bicara, maupun kognitif. Dalam beberapa kasus, stroke bahkan dapat menyebabkan kematian secara tiba-tiba jika tidak segera mendapatkan penanganan.

Berdasarkan Data Riset Kesehatan Dasar (Riskesdas) 2018, prevalensi stroke di Indonesia mencapai 10,9 per 1.000 penduduk, dengan angka kejadian tertinggi terjadi di Provinsi Sulawesi Selatan. Angka ini mengalami peningkatan dibandingkan data sebelumnya pada tahun 2013 yang menunjukkan angka 7 per 1.000 penduduk. Hal ini menunjukkan bahwa stroke menjadi beban kesehatan yang makin besar bagi masyarakat Indonesia.

Faktor-faktor risiko utama seperti hipertensi, diabetes, merokok, obesitas, serta kurangnya aktivitas fisik menjadi pemicu utama meningkatnya angka kejadian stroke. Selain itu, tingkat edukasi masyarakat mengenai gejala awal stroke dan pentingnya pencegahan masih tergolong rendah, sehingga banyak kasus baru ditemukan saat sudah parah.

Oleh karena itu, pemahaman tentang faktor-faktor risiko yang memengaruhi stroke sangat penting sebagai langkah awal dalam upaya pencegahan dan pengendalian. Peningkatan kesadaran masyarakat dan dukungan sistem layanan kesehatan menjadi kunci utama dalam menekan angka kejadian stroke di Indonesia.

**Referensi**:

- Badan Penelitian dan Pengembangan Kesehatan. (2018). Laporan Nasional Riskesdas 2018. Kementerian Kesehatan RI.

- Kementerian Kesehatan RI. (2020). Situasi dan Analisis Lanjut Penyakit Stroke. Pusat Data dan Informasi Kemenkes RI.

# Business Understanding

## Problem Statements



1.   Faktor-faktor apa saja yang paling berkontribusi terhadap risiko seseorang mengalami stroke?
2.   Apakah terdapat hubungan antara gejala (seperti nyeri dada, sesak napas, detak jantung tidak teratur, kelelahan, dan lainnya) dengan risiko stroke pada pasien?

## GOALS

1. Mengidentifikasi faktor-faktor utama yang berkontribusi terhadap risiko seseorang mengalami stroke, berdasarkan atribut seperti usia dan berbagai gejala klinis (contoh: nyeri dada, sesak napas, detak jantung tidak teratur, dan lainnya).
2. Menganalisis hubungan antara gejala yang dialami pasien dengan kemungkinan risiko stroke.

## Solution Statements

Untuk menjawab permasalahan yang telah dirumuskan, solusi yang diusulkan dalam proyek ini adalah melakukan analisis data berdasarkan riwayat kesehatan dan gejala yang dialami pasien. Langkah-langkah utama dalam solusi ini meliputi:

1. Eksplorasi data (Exploratory Data Analysis) untuk memahami distribusi variabel, mendeteksi pola-pola penting, dan mengidentifikasi hubungan awal antara gejala, kondisi kesehatan, serta faktor risiko dengan kemungkinan terjadinya stroke.

2. Penerapan inference untuk menentukan gejala dan faktor mana yang paling signifikan dalam mempengaruhi risiko stroke.

# Data Understanding

Tahap ini merupakan proses analisis data yang bertujuan untuk memperoleh pemahaman yang menyeluruh mengenai dataset sebelum melanjutkan ke tahap analisis lebih lanjut.

## Mengimport Library
"""

!pip install kaggle

pip install optuna

pip install catboost

import os
import shutil
import textwrap
import numpy as np
import zipfile
import math
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from xgboost import XGBClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import AdaBoostClassifier
import optuna
from catboost import CatBoostClassifier
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split
from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder
from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, classification_report

"""## Data Loading"""

#!/bin/bash
!curl -L -o stroke-prediction.zip\
  "https://www.kaggle.com/api/v1/datasets/download/mahatiratusher/stroke-risk-prediction-dataset"

#membuka zip menjadi folder
with zipfile.ZipFile("/content/stroke-prediction.zip", "r") as zip_ref:
    zip_ref.extractall("stroke-prediction")

#membaca csv dalam folder
data = pd.read_csv("/content/stroke-prediction/stroke_risk_dataset.csv")

# Display the first few rows
data

"""**Insight**:
Dataset ini terdiri dari 70000 data dan 18 kolom.

### Deskripsi Variable

**Deskripsi Variabel Dataset Stroke Risk Prediction**

| Variabel                     | Tipe Data  | Deskripsi                                                  |
|------------------------------|------------|------------------------------------------------------------|
| Chest Pain                   | int64     | Adanya rasa nyeri dada (1 = ya, 0 = tidak)                 |
| Shortness of Breath          | int64     | Mengalami sesak napas (1 = ya, 0 = tidak)                  |
| Irregular Heartbeat          | int64     | Irama jantung tidak teratur (1 = ya, 0 = tidak)            |
| Fatigue & Weakness           | int64     | Merasa lelah dan lemah (1 = ya, 0 = tidak)                 |
| Dizziness                   | int64     | Merasa pusing atau kepala berputar (1 = ya, 0 = tidak)     |
| Swelling (Edema)            | int64     | Pembengkakan pada tubuh (1 = ya, 0 = tidak)                 |
| Pain in Neck/Jaw/Shoulder/Back | int64  | Nyeri pada leher, rahang, bahu, atau punggung (1 = ya, 0 = tidak) |
| Excessive Sweating          | int64     | Berkeringat berlebihan (1 = ya, 0 = tidak)                  |
| Persistent Cough            | int64     | Batuk terus menerus (1 = ya, 0 = tidak)                     |
| Nausea/Vomiting             | int64     | Mual atau muntah (1 = ya, 0 = tidak)                        |
| High Blood Pressure         | int64     | Tekanan darah tinggi (1 = ya, 0 = tidak)                    |
| Chest Discomfort (Activity) | int64     | Ketidaknyamanan dada saat aktivitas (1 = ya, 0 = tidak)    |
| Cold Hands/Feet             | int64     | Tangan atau kaki terasa dingin (1 = ya, 0 = tidak)          |
| Snoring/Sleep Apnea         | int64     | Mendengkur atau apnea tidur (1 = ya, 0 = tidak)             |
| Anxiety/Feeling of Doom     | int64     | Merasa cemas atau takut (1 = ya, 0 = tidak)                 |
| Age                         | int64     | Umur pada pasien/responden                                  |
| Stroke Risk (%)             | Float      | Estimasi probabilitas terjadinya stroke dalam persen (0 - 100%) |
| At Risk                     | int64     | Status risiko stroke (1 = berisiko, 0 = tidak)              |
"""

data.info()

"""**Insight:** Dataset ini terdiri dari 16 tipedata int64, dan 1 tipedata float64.

"""

data.shape

# Membuat dataframe baru
df_filtered = pd.DataFrame(data)

"""### Deskripsi Statistik dari Data"""

# Memanggil untuk statistik data mengecek outlier.
df_filtered.describe()

"""<!-- **insight:**

1. Distribusi Usia Pasien
- Rata-rata usia pasien adalah 43 tahun, dengan rentang dari 0.08 tahun (~1 bulan) hingga 82 tahun.

- Dataset menunjukan bahwa mencakup pasien dari berbagai kelompok usia, dari bayi hingga lanjut usia.

- 75% pasien berusia di bawah 61 tahun, menandakan distribusi yang condong ke kelompok usia produktif.

2. Hipertensi dan Penyakit Jantung
- Sekitar 9.7% dari pasien memiliki hipertensi dan sekitar 5.4% memiliki penyakit jantung.


3. Rata-Rata Glukosa Darah
- Rata-rata kadar glukosa dalam darah adalah 106.1 mg/dL, dengan nilai maksimum mencapai 271.7 mg/dL.

- Hal ini menunjukkan adanya individu dengan kemungkinan kondisi hiperglikemia, yang dapat meningkatkan risiko stroke.

4. Indeks Massa Tubuh (BMI)
- Rata-rata BMI adalah 28.9, yang tergolong overweight berdasarkan klasifikasi WHO (25â€“29.9).

- Nilai maksimum BMI adalah 97.6, yang tergolong obesitas ekstrem, menandakan potensi risiko kesehatan tinggi pada sebagian kecil populasi.

5. Kejadian Stroke
- Hanya sekitar 4.9% dari pasien dalam dataset yang pernah mengalami stroke.

- Ini menunjukkan ketidakseimbangan kelas (class imbalance) yang signifikan antara pasien stroke dan non-stroke, yang perlu diperhatikan dalam analisis prediktif.

**Perlu diingat:**
- Setiap baris data dalam dataset mewakili seorang pasien yang diperiksa, tidak berarti pasien tersebut pasti mengalami stroke.

- Nilai kolom stroke adalah indikator apakah pasien pernah mengalami stroke (1) atau tidak (0).

- Pasien dengan usia sangat muda, seperti bayi, bisa ada dalam dataset, namun belum tentu mengalami stroke. -->

## EDA - Univariate Analysis

### Numerical Features
"""

df_filtered.hist(bins=50, figsize=(15,10), color= 'mediumpurple')

# Mengatur susunan agar tidak berhimpitan
plt.tight_layout()

#menampilkan plot
plt.show()

"""## EDA - Multivariate Analysis

### Membandingkan hubungan **usia** dan risiko stroke
"""

plt.figure(figsize=(8,6))
sns.barplot(
    x='At Risk (Binary)',
    y='Age',
    hue='At Risk (Binary)',
    data=df_filtered,
    palette=['#71C0BB', '#D5451B'],  # Biru pastel & cokelat pastel
    errorbar=None,
    legend=False
)
plt.title('Rata-rata Usia Berdasarkan Risiko Stroke')
plt.xlabel('Risiko Stroke (0 = Tidak, 1 = Ya)')
plt.ylabel('Rata-rata Usia')
plt.show()

plt.figure(figsize=(8,5))
sns.scatterplot(x=df_filtered['Age'], y=df_filtered['Stroke Risk (%)'], hue=df_filtered['At Risk (Binary)'])
plt.title('Stroke Risk vs Age')
plt.xlabel('Age')
plt.ylabel('Stroke Risk (%)')
plt.show()

"""**insight:**
Pasien yang mengalami stroke memiliki rata-rata usia jauh lebih tinggi dibandingkan yang tidak mengalami stroke. Rata-rata usia penderita stroke berada di atas 60 tahun. Sementara itu, rata-rata usia pasien yang tidak mengalami stroke berada di bawah 40 tahun.

### Hubungan Gejala dengan Risiko Stroke
"""

plt.figure(figsize=(10, 8))
correlation_matrix = df_filtered.corr().round(2)

# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title("Correlation Matrix", size=20)

"""**insight**: Usia dan tekanan darah tinggi merupakan faktor risiko yang cukup kuat terhadap stroke. Gejala seperti sesak napas, kelelahan, detak jantung tidak teratur, dan nyeri dada juga ikut berkontribusi, meskipun dalam tingkat korelasi yang lebih lemah.

## Data Quality Verification

### Memeriksa Data Duplikat
"""

df_filtered.duplicated().sum()

# Menampilkan data duplikat
df_filtered[df_filtered.duplicated]

"""**Insight:** Terdapat 1021 data duplikat

### Memeriksa Missing Value
"""

df_cleaned.isnull().sum()

"""**Insight**: Tidak ditemukan missing value pada dataframe diatas

### Memeriksa Outlier
"""

# Melakukan analisis statistik data setelah dihapus data duplikat dan missing value.
df_cleaned.describe()

binning_feature = [
    'Chest Pain',
    'Shortness of Breath',
    'Irregular Heartbeat',
    'Fatigue & Weakness',
    'Dizziness',
    'Swelling (Edema)',
    'Pain in Neck/Jaw/Shoulder/Back',
    'Excessive Sweating',
    'Persistent Cough',
    'Nausea/Vomiting',
    'High Blood Pressure',
    'Chest Discomfort (Activity)',
    'Cold Hands/Feet',
    'Snoring/Sleep Apnea',
    'Anxiety/Feeling of Doom'
]

#Cek data outlier

selected_cols = df_cleaned[binning_feature]

Q1 = selected_cols.quantile(0.25)
Q3 = selected_cols.quantile(0.75)
IQR = Q3 - Q1

df_filtered = df_cleaned[~((selected_cols < (Q1 - 1.5 * IQR)) | (selected_cols > (Q3 + 1.5 * IQR))).any(axis=1)]

# Jumlah fitur
n_features = len(binning_feature)

# Hitung ukuran grid (misalnya 4 kolom, sisanya baris)
n_cols = 3
n_rows = (n_features + n_cols - 1) // n_cols  # Ceiling division

# Buat grid dinamis sesuai jumlah fitur
fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(15, n_rows * 4))
fig.suptitle('Boxplot of Binary Features', fontsize=16)

# Flatten axes supaya bisa di-loop
axes = axes.flatten()

# Loop fitur dan plot
for i, feature in enumerate(binning_feature):
    sns.boxplot(data=df_cleaned, x=feature, ax=axes[i], color='skyblue')
    axes[i].set_title(f'{feature}')
    axes[i].set_xlabel('')

# Sembunyikan subplot yang tidak dipakai
for j in range(len(binning_feature), len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

"""**Insight**: Fitur-fitur biner contohnya seperti Chest Pain, Shortness of Breath, dan Irregular Heartbeat tidak memiliki outlier, karena memang hanya memiliki dua nilai yang valid (0 dan 1). Oleh karena itu, tidak perlu dilakukan deteksi atau penanganan outlier untuk fitur-fitur ini.

# Data Preparation

## Data Cleaning

### Menangani Duplikasi Data
"""

# Menghapus data duplikat
df_cleaned = df_filtered.drop_duplicates()

df_cleaned.shape

"""## Split Train dan Test dataframe

"""

from sklearn.model_selection import train_test_split
# Fitur dan target
X = df_cleaned.drop(columns=['At Risk (Binary)', 'Stroke Risk (%)'])
y = df_cleaned['At Risk (Binary)']

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Menampilkan ukuran data training dan testing dari X dan y
print("Ukuran X_train: ", X_train.shape)
print("Ukuran X_test: ", X_test.shape)
print("Ukuran y_train: ", y_train.shape)
print("Ukuran y_test: ", y_test.shape)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""## Standarisasi"""

from sklearn.preprocessing import StandardScaler
# Scaling fitur
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""# Modeling

"""

def make_evaluation(y_true, y_pred, title, target_names=None):
    if target_names is None:
        target_names = ['0', '1']

    # Gunakan label string sesuai target_names
    labels = target_names

    # Classification report pakai target_names (label string)
    print(classification_report(y_true, y_pred, target_names=target_names))

    # Plot confusion matrix dengan labels string
    fig, ax = plt.subplots(figsize=(10, 5))
    disp = ConfusionMatrixDisplay.from_predictions(
    y_true, y_pred, ax=ax, display_labels=target_names
)


    ax.set_xticklabels(target_names, rotation=90)
    ax.set_yticklabels(target_names)

    ax.grid(False)
    ax.set_title(title)
    plt.tight_layout()
    plt.show()

"""## 1. XGBoost"""

import pandas as pd
import optuna
from sklearn.metrics import accuracy_score
from xgboost import XGBClassifier
from sklearn.preprocessing import LabelEncoder

# Step 1: Encode target label string ke angka
le = LabelEncoder()
y_train_encoded = le.fit_transform(y_train)
y_test_encoded = le.transform(y_test)

# Dapatkan nama kelas dari LabelEncoder
target_nama = le.classes_
num_class = len(target_nama)

# Step 2: Convert fitur ke numpy array jika masih DataFrame
X_train_scaled = X_train_scaled.values if isinstance(X_train_scaled, pd.DataFrame) else X_train_scaled
X_test_scaled = X_test_scaled.values if isinstance(X_test_scaled, pd.DataFrame) else X_test_scaled

# Fungsi objective untuk Optuna
def objective(trial):
    max_depth = trial.suggest_int('max_depth', 3, 15)
    n_estimators = trial.suggest_int('n_estimators', 50, 200)
    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)
    random_state = 42  # fix supaya reproducible, jangan di-tune

    model_xgb = XGBClassifier(
        max_depth=max_depth,
        n_estimators=n_estimators,
        learning_rate=learning_rate,
        random_state=random_state,
        n_jobs=-1,
        eval_metric='mlogloss',
        objective='multi:softmax',
        num_class=num_class
    )

    model_xgb.fit(X_train_scaled, y_train_encoded)
    y_pred = model_xgb.predict(X_test_scaled)
    accuracy = accuracy_score(y_test_encoded, y_pred)
    return accuracy


# Jalankan optimasi Optuna
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=10)

# Step 9: Tampilkan hasil terbaik hyperparameter dan akurasi tertinggi
print("Best hyperparameters: ", study.best_params)
print("Best accuracy: ", study.best_value)

# Memanggil fungsi XGBClassifier dari library sklearn
model_xgb = XGBClassifier(max_depth = 6, n_estimators = 140,
                          random_state = 9, learning_rate = 0.09165493299025286, n_jobs = -1)

# Melatih model XGBoost dengan data training pada X dan y
model_xgb.fit(X_train_scaled, y_train_encoded)

# Prediksi dengan model terbaik
pred_xgb = model_xgb.predict(X_test_scaled)

# Ubah encoded prediction dan true label ke label string
y_pred_labels = le.inverse_transform(pred_xgb)
y_test_labels = le.inverse_transform(y_test_encoded)

# Menampilkan akurasi model
xgb = accuracy_score(y_test_encoded, pred_xgb)
accuracy_xgboost= round(accuracy_score(y_test_encoded, pred_xgb)*100,2)
print("hasil akurasi model xgboost: ", accuracy_xgboost,"%")

# Pastikan target_nama berisi array string
target_nama = [str(cls) for cls in le.classes_]

# Panggil evaluasi
make_evaluation(y_test_labels, y_pred_labels, "Confusion Matrix Menggunakan Algoritma XGBoost", target_names=target_nama)

"""**Insight**:

- True Negatives (TN): 4,732 â€” model dengan benar mengenali orang yang tidak berisiko stroke.

- True Positives (TP): 8,899 â€” model dengan benar mengenali orang yang berisiko stroke.

- False Negatives (FN): 58 â€” orang yang seharusnya berisiko stroke tapi model tidak mengenalinya â†’ ini paling krusial karena bisa fatal.

- False Positives (FP): 107 â€” orang yang tidak berisiko stroke tapi dikira berisiko â†’ lebih dapat diterima dibanding FN

## 2. Random Forest
"""

# Memanggil fungsi RandomForestClassifier dari library sklearn
model_rf = RandomForestClassifier(
    n_estimators=100,
    criterion="entropy",
    max_depth=10,
    random_state=50
)

# Melatih model Random Forest dengan data training pada X dan y
model_rf.fit(X_train_scaled, y_train)

"""- Model Random Forest diatur untuk membangun 100 pohon keputusan secara paralel, sehingga meningkatkan stabilitas dan akurasi model karena prediksi akhir diperoleh dari hasil voting banyak pohon.

- Kriteria pemisahan yang digunakan adalah "entropy", yaitu berdasarkan perhitungan informasi (information gain). Ini berarti setiap pohon akan mencari cara membagi data yang paling mengurangi ketidakpastian, sehingga hasil klasifikasinya menjadi lebih informatif.

- Parameter max_depth=10 membatasi kedalaman maksimum setiap pohon agar tidak terlalu kompleks. Tujuannya adalah untuk mencegah overfitting, yaitu kondisi di mana model terlalu menyesuaikan diri pada data training dan gagal bekerja baik pada data baru.

- Dengan mengatur random_state=50, proses pelatihan menjadi konsisten dan dapat direproduksi karena pemilihan sampel acak akan selalu menggunakan acuan (seed) yang sama.

- Terakhir, jika digunakan, parameter n_jobs=-1 akan memanfaatkan seluruh inti CPU yang tersedia untuk mempercepat proses pelatihan, terutama saat menangani dataset berukuran besar.
"""

# Memprediksi hasil menggunakan data testing berdasarkan model yang telat dilatih
pred_rf = model_rf.predict(X_test_scaled)

# Menampilkan akurasi model
accuracy_rf= round(accuracy_score(y_test, pred_rf)*100,2)
print("hasil akurasi model Random Forest: ", accuracy_rf,"%")

print(set(type(x) for x in y_test))     # Set tipe data di y_test
print(set(type(x) for x in pred_rf))    # Set tipe data di pred_rf

print(y_test[:10])   # Contoh 10 elemen pertama y_test
print(pred_rf[:10])  # Contoh 10 elemen pertama pred_rf

make_evaluation(y_test, pred_rf, title="Confusion Matrix Menggunakan Algoritma Random Forest")

"""**Insight:**
- False Positives (FP): 677 â€” orang yang tidak berisiko stroke tapi model menganggap mereka berisiko.

- False Negatives (FN): 431 â€” orang yang sebenarnya berisiko stroke tapi tidak terdeteksi (lebih berbahaya secara medis).

- True Positives (TP): 8,526 dan True Negatives (TN): 4,162 menunjukkan model cukup baik menangani kedua kelas.

## 3. SVM
"""

# Encode label target string ke angka
le = LabelEncoder()
y_train_encoded = le.fit_transform(y_train)
y_test_encoded = le.transform(y_test)

# Dapatkan nama kelas
target_names = le.classes_

# Convert fitur ke numpy array jika masih DataFrame
X_train_scaled = X_train_scaled.values if isinstance(X_train_scaled, pd.DataFrame) else X_train_scaled
X_test_scaled = X_test_scaled.values if isinstance(X_test_scaled, pd.DataFrame) else X_test_scaled

# Buat model SVM dengan kernel 'rbf' (default)
model_svm = SVC(kernel='rbf', random_state=42)

# Latih model
model_svm.fit(X_train_scaled, y_train_encoded)

# Prediksi data test
y_pred_encoded = model_svm.predict(X_test_scaled)

# Ubah hasil prediksi encoded ke label string
y_pred_labels = le.inverse_transform(y_pred_encoded)
y_test_labels = le.inverse_transform(y_test_encoded)

model_svm.fit(X_train_scaled, y_train_encoded)

# Hitung akurasi
accuracy_svm = round(accuracy_score(y_test_encoded, y_pred_encoded)*100,2)
print(f"Akurasi model SVM: {accuracy_svm}%")

# Tampilkan evaluasi
target_names = [str(cls) for cls in le.classes_]

make_evaluation(y_test_labels, y_pred_labels, "Confusion Matrix Menggunakan Algoritma SVM", target_names=target_names)

"""**Insight:**
- False Positive (78): Sebanyak 78 orang yang sebenarnya tidak berisiko diprediksi berisiko. Ini bisa berdampak ke over-treatment, tapi relatif tidak berbahaya.

- False Negative (56): Sebanyak 56 orang yang sebenarnya berisiko diprediksi tidak berisiko. Ini adalah kesalahan yang lebih serius karena bisa menyebabkan keterlambatan penanganan.

- True Negative (TN): Sebanyak 4761 orang yang
Artinya orang tersebut memang tidak berisiko terkena stroke, dan model benar memprediksi mereka sebagai tidak berisiko.

- True Positive (TP): Sebanyak 8901 orang yang memang berisiko terkena stroke, dan model berhasil mengklasifikasikan mereka dengan benar.

# Evaluasi dan Pemilihan Model
"""

# Membentuk DataFrame berisi model dengan akurasinya
models = pd.DataFrame({
    "Model": ["XGBoost", "Random Forest", "SVM"],
    "Akurasi": [accuracy_xgboost, accuracy_rf, accuracy_svm]
})

# Mengurutkan data berdasarkan akurasi dari tertinggi ke terendah
models.sort_values(by = "Akurasi", ascending = False)

"""**Insight:** Saya memilih model XGBoost karena model inferencenya cepat, akurat, dan stabil untuk predictive analytics."""

plt.figure(figsize=(8, 6))


custom_palette = ['#CB0404', '#096B68', '#F49BAB']

barplot = sns.barplot(data=models, x="Model", y="Akurasi", palette=custom_palette)

# Menambahkan label angka di atas bar
for index, value in enumerate(models["Akurasi"]):
    barplot.text(index, value + 0.02, f"{value:.4f}", color="black", ha="center")

# Judul dan label
plt.title("Perbandingan Akurasi dari ketiga Model")
plt.xlabel("Model")
plt.ylabel("Akurasi")

plt.tight_layout()
plt.show()

"""# Menjawab Permasalahan

## 1. Faktor-faktor apa saja yang paling berkontribusi terhadap risiko seseorang mengalami stroke?
"""

#signifikan faktor dari model XGboost (model Terbaik) tersebut yang menggambarkan responden Terkena cardiovascular
feat_importances = pd.Series(model_xgb.feature_importances_,index=X.columns)
feat_importances.nlargest(10).plot(kind='barh')

"""**Insight:** Faktor yang paling berkontribusi seseorang mengalami Stroke adalah Faktor Umur

## 2. Apakah terdapat hubungan antara gejala (seperti nyeri dada, sesak napas, detak jantung tidak teratur, kelelahan, dan lainnya) dengan risiko stroke pada pasien?
"""

import numpy as np

def infer_stroke_risk(model, label_encoder):
    print("Masukkan data berikut untuk prediksi risiko stroke Anda:\n")

    # Data numerik umum
    age = float(input("Umur (tahun): "))

    # Pertanyaan gejala (biner: 1 = Ya, 0 = Tidak)
    chest_pain = int(input("Apakah Anda mengalami nyeri dada? (1=Ya, 0=Tidak): "))
    short_breath = int(input("Apakah Anda sering sesak napas? (1=Ya, 0=Tidak): "))
    irregular_heartbeat = int(input("Apakah detak jantung Anda tidak teratur? (1=Ya, 0=Tidak): "))
    fatigue = int(input("Apakah Anda sering merasa lelah atau lemas? (1=Ya, 0=Tidak): "))
    dizziness = int(input("Apakah Anda sering merasa pusing? (1=Ya, 0=Tidak): "))
    swelling = int(input("Apakah Anda mengalami pembengkakan (edema)? (1=Ya, 0=Tidak): "))
    pain_upper = int(input("Apakah ada nyeri di leher, rahang, bahu, atau punggung? (1=Ya, 0=Tidak): "))
    sweating = int(input("Apakah Anda berkeringat berlebihan? (1=Ya, 0=Tidak): "))
    cough = int(input("Apakah Anda mengalami batuk terus-menerus? (1=Ya, 0=Tidak): "))
    nausea = int(input("Apakah Anda sering merasa mual atau muntah? (1=Ya, 0=Tidak): "))
    high_bp = int(input("Apakah Anda memiliki tekanan darah tinggi? (1=Ya, 0=Tidak): "))
    chest_discomfort = int(input("Apakah Anda merasa tidak nyaman di dada saat beraktivitas? (1=Ya, 0=Tidak): "))
    cold_extremities = int(input("Apakah tangan atau kaki Anda sering dingin? (1=Ya, 0=Tidak): "))
    apnea = int(input("Apakah Anda mendengkur atau punya sleep apnea? (1=Ya, 0=Tidak): "))
    anxiety = int(input("Apakah Anda merasa cemas berlebihan atau firasat buruk? (1=Ya, 0=Tidak): "))

    # Susun fitur input (urutan sesuai model pelatihan)
    fitur_input = np.array([[
        age, chest_pain, short_breath, irregular_heartbeat, fatigue, dizziness,
        swelling, pain_upper, sweating, cough, nausea,
        high_bp, chest_discomfort, cold_extremities, apnea, anxiety
    ]])

    # Prediksi
    pred_encoded = model.predict(fitur_input)
    pred_label = label_encoder.inverse_transform(pred_encoded)

    print("\nðŸ§  Prediksi risiko stroke Anda adalah:", pred_label[0])

infer_stroke_risk(model_xgb, le)

"""**Keterangan**:
0: Tidak Stroke
1: Memiliki Resiko Stroke

"""

import joblib

# Simpan model ke file
joblib.dump(model_xgb, 'model_stroke_xgb.pkl')

# Simpan label encoder ke file (jika diperlukan)
joblib.dump(le, 'label_encoder.pkl')